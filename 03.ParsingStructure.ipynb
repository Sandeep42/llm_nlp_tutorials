{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6a6fbcc-fb93-4fd7-9f64-e1fe501b0563",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8195cdfa-9642-4ecf-a85f-9daa6badae71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from typing import List, Literal, Annotated\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.tools import tool\n",
    "import getpass\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from prompt_poet import Prompt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from devtools import pprint\n",
    "from typing import List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdfd808f-5c94-4ee6-9c34-28605a0c4ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "groq_api_key = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f4d071b-2885-4201-bb0e-f83fd51c87de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import PyPDF2\n",
    "\n",
    "def download_arxiv_pdf(arxiv_id, save_path):\n",
    "    # Construct the arXiv PDF URL\n",
    "    url = f'https://arxiv.org/pdf/{arxiv_id}.pdf'\n",
    "    \n",
    "    # Send a GET request to download the PDF\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Write the content of the response (PDF) to a file\n",
    "        with open(save_path, 'wb') as pdf_file:\n",
    "            pdf_file.write(response.content)\n",
    "        print(f\"PDF downloaded successfully and saved to {save_path}\")\n",
    "    else:\n",
    "        print(f\"Failed to download PDF. Status code: {response.status_code}\")\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    # Open the PDF file\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "\n",
    "        # Loop through all the pages\n",
    "        for page_num in range(len(reader.pages)):\n",
    "            page = reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c057e7a-6f67-4638-8ff5-e4c76b0705b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF downloaded successfully and saved to tmp/1706.03762.pdf\n"
     ]
    }
   ],
   "source": [
    "download_arxiv_pdf(\"1706.03762\",\"tmp/1706.03762.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8e93e7c-0267-4ec5-8e6f-297374837b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_text = extract_text_from_pdf(\"tmp/1706.03762.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f8988a5-a281-40ee-8c9e-f9c9768715b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and figures in this paper solely for use in journalistic or\n",
      "scholarly works.\n",
      "Attention Is All You Need\n",
      "Ashish Vaswani∗\n",
      "Google Brain\n",
      "avaswani@google.comNoam Shazeer∗\n",
      "Google Brain\n",
      "noam@google.comNiki Parmar∗\n",
      "Google Research\n",
      "nikip@google.comJakob Uszkoreit∗\n",
      "Google Research\n",
      "usz@google.com\n",
      "Llion Jones∗\n",
      "Google Research\n",
      "llion@google.comAidan N. Gomez∗ †\n",
      "University of Toronto\n",
      "aidan@cs.toronto.eduŁukasz Kaise\n"
     ]
    }
   ],
   "source": [
    "print(pdf_text[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6269a01-4367-4605-a0b1-c81aeb4e8a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "def estimate_context_length(text):\n",
    "    # Load GPT-2 tokenizer\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "    # Tokenize the text\n",
    "    tokens = tokenizer.encode(text)\n",
    "    # Return the number of tokens\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d6bc9ef5-1cb0-481b-884b-458451cdecab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sandeep/anaconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (10540 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10540"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_context_length(pdf_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c321d367-240a-433a-9aa6-78a4c9aae5b9",
   "metadata": {},
   "source": [
    "Can we parse the structure of the paper, extract title, abstract, sections and their subsections?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9369d794-1ff1-456b-8be9-b1d83303e763",
   "metadata": {},
   "source": [
    "#### Zero shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a3df9938-802a-452a-b12d-1b67ebb51765",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_template = \"\"\"\n",
    "- name: system instructions\n",
    "  role: system\n",
    "  content: |\n",
    "   You are an expert in parsing a given research article into title, abstract, section and subsections.\n",
    "\n",
    "- name: user query\n",
    "  role: user\n",
    "  content: |\n",
    "   Please extract properties defined in 'Parser' function from the text.\n",
    "   {{ escape_special_characters(text) }}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9a847cf0-53cf-486d-9fed-75335956d2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Section"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4c147be8-230d-462c-b930-89863134ae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Subsection(BaseModel):\n",
    "#     subsection_title: Optional[str] = Field(description=\"Title of subsection\")\n",
    "\n",
    "class Section(BaseModel):\n",
    "    section_tile: Optional[str] = Field(description=\"Title of section. Keep it short and within 2-3 words.\")\n",
    "    # subsections: Optional[List[Subsection]] = Field(description=\"List of sub-sections within the section\")\n",
    "    \n",
    "class Parser(BaseModel):\n",
    "    title: str = Field(description=\"The title of the research article\")\n",
    "    authors: List[str] = Field(description=\"List of Authors of the research article, keep only the name\")\n",
    "    abstract: str = Field(description=\"Abstract of the research article\")\n",
    "    sections: Optional[List[Section]] = Field(description=\"Main Section mentioned in the text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "df0a3a82-fa33-4e36-bd8a-f4c1b1cfcb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = Prompt(\n",
    "    raw_template=raw_template,\n",
    "    template_data={\"text\": pdf_text[0:15000]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2e512532-8f74-425d-ae09-fc3615f60485",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_parser = ChatGroq(temperature=0, model_name=\"mixtral-8x7b-32768\",api_key=groq_api_key).with_structured_output(Parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "846ed14e-22e4-4b9e-b73f-bfcd23a05db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm_parser.invoke(prompt.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8ce8d752-c087-44f5-9471-d33c3fb70e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parser(\n",
      "    title='Attention is All You Need',\n",
      "    authors=[\n",
      "        'Ashish Vaswani∗',\n",
      "        'Noam Shazeer∗',\n",
      "        'Niki Parmar∗',\n",
      "        'Jakob Uszkoreit∗',\n",
      "        'Llion Jones∗',\n",
      "        'Aidan N. Gomez∗ †',\n",
      "        'Łukasz Kaiser∗',\n",
      "        'Illia Polosukhin∗ ‡',\n",
      "    ],\n",
      "    abstract=(\n",
      "        'The dominant sequence transduction models are based on complex recurrent or convolutional neural networks tha'\n",
      "        't include an encoder and a decoder. The best performing models also connect the encoder and decoder through a'\n",
      "        'n attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attenti'\n",
      "        'on mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation t'\n",
      "        'asks show these models to be superior in quality while being more parallelizable and requiring significantly '\n",
      "        'less time to train.'\n",
      "    ),\n",
      "    sections=[\n",
      "        Section(\n",
      "            section_tile='Abstract',\n",
      "        ),\n",
      "        Section(\n",
      "            section_tile='Introduction',\n",
      "        ),\n",
      "        Section(\n",
      "            section_tile='Background',\n",
      "        ),\n",
      "        Section(\n",
      "            section_tile='Model Architecture',\n",
      "        ),\n",
      "        Section(\n",
      "            section_tile='Encoder and Decoder Stacks',\n",
      "        ),\n",
      "        Section(\n",
      "            section_tile='Attention',\n",
      "        ),\n",
      "        Section(\n",
      "            section_tile='Position-wise Feed-Forward Networks',\n",
      "        ),\n",
      "        Section(\n",
      "            section_tile='Embeddings and Softmax',\n",
      "        ),\n",
      "    ],\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "3096bdf9-7f67-499f-b185-e565b43cd701",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = Prompt(\n",
    "    raw_template=raw_template,\n",
    "    template_data={\"text\": pdf_text[15000:25000]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "567da8a9-0a52-447d-a310-a32c06cb41da",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_parser = ChatGroq(temperature=0, model_name=\"mixtral-8x7b-32768\",api_key=groq_api_key).with_structured_output(Parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b623717d-c9a0-4cb0-bcbe-fc48b1f3f0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm_parser.invoke(prompt.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "4f246457-6733-412a-9bf1-b900b0fba18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parser(\n",
      "    title='Self-Attention (restricted)',\n",
      "    authors=[\n",
      "        'Ashish Vaswani',\n",
      "        'Noam Shazeer',\n",
      "        'Niki Parmar',\n",
      "        'Jakob Uszkoreit',\n",
      "        'Llion Jones',\n",
      "        'Aidan N. Gomez',\n",
      "        'Lukasz Kaiser',\n",
      "        'Illia Polosukhin',\n",
      "    ],\n",
      "    abstract=(\n",
      "        'In this work, we introduce a new type of attention mechanism, called self-attention, which allows the model t'\n",
      "        'o focus on different parts of the input sequence when producing an output. We show that self-attention can be'\n",
      "        ' used to improve the performance of machine translation models, and we also demonstrate its effectiveness on '\n",
      "        'other tasks such as language modeling and text classification.'\n",
      "    ),\n",
      "    sections=[\n",
      "        Section(\n",
      "            section_tile='Introduction',\n",
      "        ),\n",
      "        Section(\n",
      "            section_tile='Self-Attention Mechanism',\n",
      "        ),\n",
      "        Section(\n",
      "            section_tile='Machine Translation Experiments',\n",
      "        ),\n",
      "        Section(\n",
      "            section_tile='Other Tasks Experiments',\n",
      "        ),\n",
      "        Section(\n",
      "            section_tile='Conclusion',\n",
      "        ),\n",
      "    ],\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357190f9-0690-45b5-b34c-a9d362099903",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
